{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import shapefile\n",
    "import json\n",
    "import pandas as pd\n",
    "import os\n",
    "import zipfile\n",
    "import codecs\n",
    "import io\n",
    "\n",
    "from bokeh.plotting import figure, output_file, show, hplot\n",
    "from bokeh.models import Rect, HoverTool, ColumnDataSource\n",
    "\n",
    "from collections import OrderedDict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "__author__ = 'James Macdonald'\n",
    "__copyright__ = 'Copyright 2015, James Macdonald'\n",
    "__license__ = 'GPL'\n",
    "__version__ = '0.1'\n",
    "__maintainer__ = 'James Macdonald'\n",
    "__email__ = 'maacca@gmail.com'\n",
    "__thanks__ = ['Lee Rhiannon','Freya Newman','Denise Abou Hamad']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def shapes_from_zip(shapezip):\n",
    "    '''Reads shapefiles packaged in zip'''\n",
    "    zipshape = zipfile.ZipFile(shapezip)\n",
    "    ishp = [f for f in zipshape.namelist() if '.shp' in f][0]\n",
    "    ishx = [f for f in zipshape.namelist() if '.shx' in f][0]\n",
    "    idbf = [f for f in zipshape.namelist() if '.dbf' in f][0]\n",
    "    partdic = {}\n",
    "    for part in [ishp,ishx,idbf]:\n",
    "        partdic[part] = io.BytesIO(zipshape.read(part))\n",
    "    return shapefile.Reader(shp=partdic[ishp],shx=partdic[ishx],dbf=partdic[idbf])\n",
    "\n",
    "def data_from_zip(datazip):\n",
    "    '''Extracts a dataframe from a zipfile assuming csv format'''\n",
    "    zipdata = zipfile.ZipFile(datazip)\n",
    "    df_dic = {}\n",
    "    for pos,title in enumerate(zipdata.namelist()):\n",
    "        df_dic[pos] = pd.read_csv(io.BytesIO(zipdata.read(title)), skiprows=3)\n",
    "        df_dic[pos] = df_dic[pos][[col for col in df_dic[pos].columns.values if 'Unnamed:' in col]]\n",
    "    return df_dic\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Extract school data as dummy data \n",
    "def get_test_data():\n",
    "    df = pd.read_csv('Data/School_Completions_By_Postcode.csv',skiprows=3)\n",
    "    df = df[[col for col in df.columns.values if 'Unnamed' not in col]]\n",
    "    df = df[pd.notnull(df['Total'])]\n",
    "    df['postcode'] = df['Highest Year of School Completed (HSCP)'].str.split(\", \").apply(lambda x: x[0])\n",
    "    df = df[df['postcode'].apply(lambda x: x.isnumeric())]\n",
    "    df['State'] = df['Highest Year of School Completed (HSCP)'].str.split(\", \").apply(lambda x: x[1])\n",
    "    return df\n",
    "\n",
    "df = get_test_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def shapefile_to_dataframe(processed_shapefile):\n",
    "    '''Return a pandas dataframe from a shapefile object\n",
    "    \n",
    "    Three columns returned\n",
    "    df['lat'] - the latitude of each point of the shape\n",
    "    df['lng'] - the longitude of each point of the shape\n",
    "    df['name'] - the name of the shape\n",
    "    '''\n",
    "    df = pd.DataFrame()\n",
    "    shape_records = processed_shapefile.shapeRecords()\n",
    "    shapes = [i.shape for i in shape_records]\n",
    "    records = [i.record for i in shape_records]\n",
    "    if str(records[0][1]) == '105051100':\n",
    "        record_pos = 2\n",
    "    else:\n",
    "        record_pos = 1\n",
    "    #shapes = [i.shape for i in shape_records]\n",
    "    #shapes = pd.Series(shapes)\n",
    "    locs = []\n",
    "    rec = []\n",
    "    for shapeObj,record in zip(shapes, records):\n",
    "        points = []\n",
    "        try:\n",
    "            num_parts = len(shapeObj.parts)\n",
    "        except:\n",
    "            continue\n",
    "        end = len(shapeObj.points) - 1\n",
    "        segments = list(shapeObj.parts) + [end]\n",
    "        for i in range(num_parts):\n",
    "            points.append(shapeObj.points[ segments[i]:segments[i+1]])\n",
    "        for point in points:\n",
    "            locs.append(point)\n",
    "            for_rec = record[record_pos]\n",
    "            rec.append(for_rec)\n",
    "    lat = []\n",
    "    lng = []\n",
    "    for loc in locs:\n",
    "        lat.append([pair[0] for pair in loc])\n",
    "        lng.append([pair[1] for pair in loc])\n",
    "    df['lat'] = lat\n",
    "    df['lng'] = lng\n",
    "    df['name'] = rec\n",
    "    return(df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_from_df(output_file_name, df, size):\n",
    "    '''Creates an html file with a choropleth map in a selected region\n",
    "\n",
    "    Variables: \n",
    "    output_file_name - the location of the file to be saved\n",
    "    variable - numeric variable against which to shade the postcodes\n",
    "    scope - determines how large an area is covered by the generated map\n",
    "    geo_filter - if a scope is given, this specifies the area\n",
    "    size = how big in pixels the resulting map should be\n",
    "    \n",
    "    '''\n",
    "    data_source = ColumnDataSource (\n",
    "    data = dict(\n",
    "            lat_list=df['lat'],\n",
    "            lng_list=df['lng'],\n",
    "            #color=colors['hex'],\n",
    "            name=df['name'],\n",
    "            #data=colors[variable],\n",
    "            #suburbs=colors['suburb'],\n",
    "            #state=colors['state']\n",
    "    )\n",
    "    )\n",
    "    output_file(output_file_name)\n",
    "    #vaariable = '$'+variable\n",
    "    TOOLS=\"pan,wheel_zoom,box_zoom,reset,hover,save\"\n",
    "    #if geo_filter == 'None':\n",
    "    #    title_str = 'Australia'\n",
    "    #else:\n",
    "    #    title_str = geo_filter\n",
    "    p = figure(#title=variable.capitalize()+\" in \"+title_str.capitalize()+\" by Postcode\", \n",
    "        plot_width = size, plot_height=size, tools=TOOLS)\n",
    "    #p.xgrid.grid_line_color = None\n",
    "    #p.ygrid.grid_line_color = None\n",
    "    p.patches('lat_list',\n",
    "              'lng_list',\n",
    "              fill_color = 'black', fill_alpha=0.7,\n",
    "              line_color = 'green', line_width = 0.5,\n",
    "             source = data_source)\n",
    "    hover = p.select(dict(type=HoverTool))\n",
    "    hover.point_policy = \"follow_mouse\"\n",
    "    hover.tooltips = OrderedDict([\n",
    "            (\"Name\", \"@name\"),\n",
    "            #(variable, '@data'),\n",
    "            #(\"Suburbs\",'@suburbs'),\n",
    "            #(\"State\",'@state'),\n",
    "    ])\n",
    "    show(p)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_SA1_lookup(processed_shapefile):\n",
    "    sa1_lookup = pd.DataFrame()\n",
    "    a = pd.Series(processed_shapefile.records())\n",
    "    for i in range(len(a[0])):\n",
    "        sa1_lookup[i] = a.apply(lambda x: x[i])\n",
    "    sa1_lookup.columns = ['SA1 Code','SA1 Suffix','SA1 Prefix','SA2 Code','SA2','SA3 Code','SA3','SA4 Code','SA4',\n",
    "               'StatePart Code','StatePart','State Code','State','Number']\n",
    "    return sa1_lookup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def sa1_shapefile_to_dataframe(processed_shapefile, all_levels=True, get_electorates=True):\n",
    "    '''Read the shapefile relating to SA1 statistical areas'''\n",
    "    df = pd.DataFrame()\n",
    "    shape_records = processed_shapefile.shapeRecords()\n",
    "    shapes = [i.shape for i in shape_records]\n",
    "    records = [i.record for i in shape_records]\n",
    "    locs = []\n",
    "    rec = []\n",
    "    state=[]\n",
    "    for shapeObj,record in zip(shapes, records):\n",
    "        points = []\n",
    "        try:\n",
    "            num_parts = len(shapeObj.parts)\n",
    "        except:\n",
    "            continue\n",
    "        end = len(shapeObj.points) - 1\n",
    "        segments = list(shapeObj.parts) + [end]\n",
    "        for i in range(num_parts):\n",
    "            points.append(shapeObj.points[ segments[i]:segments[i+1]])\n",
    "        for point in points:\n",
    "            locs.append(point)\n",
    "            for_rec = record[0]\n",
    "            for_state = record[12]\n",
    "            rec.append(for_rec)\n",
    "            state.append(for_state)\n",
    "    lat = []\n",
    "    lng = []\n",
    "    for loc in locs:\n",
    "        lat.append([pair[0] for pair in loc])\n",
    "        lng.append([pair[1] for pair in loc])\n",
    "    df['lat'] = lat\n",
    "    df['lng'] = lng\n",
    "    df['name'] = rec\n",
    "    df['state'] = state\n",
    "    \n",
    "    \n",
    "    #extract all the layers of the record and merge back into the dataframe\n",
    "    if all_levels == True:\n",
    "        df = df.merge(get_SA1_lookup(processed_shapefile).drop_duplicates(), how=\"left\", left_on='name', right_on='SA1 Code')\n",
    "    # read in the postcode and electorate files to build out the frame\n",
    "    sa1_pc = pd.read_csv('Data/POA_2011_AUST.csv')\n",
    "    sa1_pc['merger'] = sa1_pc['SA1_MAINCODE_2011'].apply(lambda x: str(x))\n",
    "    sa1_pc = sa1_pc.drop_duplicates()\n",
    "    if get_electorates == True:\n",
    "        pc_2_elec = pd.read_csv('Data/pc_2_electorate.csv')\n",
    "        pc_2_elec['postcode'] = pc_2_elec['postcode'].astype(str).str.zfill(4)\n",
    "        pc_2_elec = pc_2_elec.drop_duplicates()\n",
    "        sa1_pc = pd.merge(pc_2_elec, sa1_pc,how=\"left\", left_on=\"postcode\", right_on='merger').drop_duplicates()\n",
    "        #df = df.merge(pc_2_elec[['postcode','Electorate']], left_on=\"POA_NAME_2011\",right_on='postcode')\n",
    "        df = df.merge(sa1_pc, how=\"left\", left_on='name', right_on='merger')\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def set_hue(cdf,selected_var, cmaptype = matplotlib.cm.GnBu):\n",
    "    cdf = cdf[[selected_var]]\n",
    "    colours = cmaptype(cdf[\n",
    "            selected_var\n",
    "        ]/cdf[\n",
    "            selected_var\n",
    "        ].max())\n",
    "    for pos,val in enumerate(['R','G','B','Int']):\n",
    "        cdf[val] = colours[:,pos]\n",
    "    cdf['rgb'] = list(zip(cdf['R'],cdf['G'],cdf['B'],cdf['Int']))\n",
    "    cdf['hex'] = cdf['rgb'].apply(lambda x: matplotlib.colors.rgb2hex(x))\n",
    "    return cdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def plot_sa1_from_df(output_file_name, df, variable,\n",
    "                     sa1_df = sa1_frame, scope='Electorate',\n",
    "                     geo_filter=['Grayndler'], size=1000, icmap=matplotlib.cm.GnBu):\n",
    "    '''Creates an html file with a choropleth map in a selected region\n",
    "\n",
    "    Variables: \n",
    "    output_file_name - the location of the file to be saved\n",
    "    variable - numeric variable against which to shade the postcodes\n",
    "    scope - determines how large an area is covered by the generated map\n",
    "    geo_filter - if a scope is given, this specifies the area\n",
    "    size = how big in pixels the resulting map should be\n",
    "    \n",
    "    '''\n",
    "    #Trim the geodata to only those SA1s within the area specified\n",
    "    if type(geo_filter)==list:\n",
    "        sa1_df = sa1_df[sa1_df[scope].isin(geo_filter)]\n",
    "    else:\n",
    "        sa1_df = sa1_df[sa1_df[scope] == geo_filter]\n",
    "    \n",
    "    #trim the postcodes to only those in scope, then get rid of Lord Howe Island because it's so remote\n",
    "    df = df[df['postcode'].isin(sa1_df['postcode'])]\n",
    "    df = df.merge(set_hue(df,variable,cmaptype=icmap),how=\"left\", on=variable)\n",
    "    df = df.drop_duplicates()\n",
    "    df = pd.merge(sa1_df, df, how=\"left\", on=\"postcode\")\n",
    "    df = df[df['postcode'] != '2898']\n",
    "    df['lat'] = df['lat'].apply(lambda x: repr(x))\n",
    "    df['lng'] = df['lng'].apply(lambda x: repr(x))\n",
    "    df = df.drop_duplicates()\n",
    "    df['lat'] = df['lat'].apply(lambda x: literal_eval(x))\n",
    "    df['lng'] = df['lng'].apply(lambda x: literal_eval(x))\n",
    "    \n",
    "    data_source = ColumnDataSource (\n",
    "    data = dict(\n",
    "            lat_list=df['lat'],\n",
    "            lng_list=df['lng'],\n",
    "            color=df['hex'],\n",
    "            name=df['name'],\n",
    "            data=df[variable],\n",
    "            postcode=df['postcode'],\n",
    "            electorate=df['Electorate'],\n",
    "            #suburbs=colors['suburb'],\n",
    "            #state=colors['state']\n",
    "    )\n",
    "    )\n",
    "    output_file(output_file_name)\n",
    "    #vaariable = '$'+variable\n",
    "    TOOLS=\"pan,wheel_zoom,box_zoom,reset,hover,save\"\n",
    "    #if geo_filter == 'None':\n",
    "    #    title_str = 'Australia'\n",
    "    #else:\n",
    "    #    title_str = geo_filter\n",
    "    p = figure(#title=variable.capitalize()+\" in \"+title_str.capitalize()+\" by Postcode\", \n",
    "        plot_width = size, plot_height=size, tools=TOOLS)\n",
    "    #p.xgrid.grid_line_color = None\n",
    "    #p.ygrid.grid_line_color = None\n",
    "    p.patches('lat_list',\n",
    "              'lng_list',\n",
    "              fill_color = 'color', fill_alpha=0.7,\n",
    "              line_color = 'green', line_width = 0.5,\n",
    "             source = data_source)\n",
    "    hover = p.select(dict(type=HoverTool))\n",
    "    hover.point_policy = \"follow_mouse\"\n",
    "    hover.tooltips = OrderedDict([\n",
    "            (\"Name\", \"@name\"),\n",
    "            (variable, '@data'),\n",
    "            ('Postcode', \"@postcode\"),\n",
    "            ('Electorate',\"@electorate\")\n",
    "            #(\"Suburbs\",'@suburbs'),\n",
    "            #(\"State\",'@state'),\n",
    "    ])\n",
    "    legend=figure(width=100,height=size)\n",
    "    legend.toolbar_location=None\n",
    "    legend.rect(x=0.5,y=df[variable],color=df['hex'],height=10,width=10)\n",
    "    legend.xaxis.visible = None\n",
    "    legend.xgrid.grid_line_color = None\n",
    "    legend.ygrid.grid_line_color = None\n",
    "    layout = hplot(p,legend)\n",
    "    show(layout)\n",
    "    return(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62232\n",
      "62232\n",
      "62232\n",
      "81"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jmacdonald/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/jmacdonald/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "103\n",
      "81\n",
      "9862\n",
      "54.518479819002096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jmacdonald/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    start = timeit.default_timer()\n",
    "    sa1_frame = sa1_shapefile_to_dataframe(shapes_from_zip('Shapefiles/1270055001_sa1_2011_aust_shape.zip'))\n",
    "    #Plotting example - Lord Howe Island excluded\n",
    "    adf = plot_sa1_from_df('Grayndler_test.html', df, 'Did not go to school', \n",
    "                 sa1_df = example, scope='Electorate', geo_filter=['Sydney','Barton','Watson','Reid','Grayndler','Wentworth','Kingsford Smith'],\n",
    "                 size=1000, icmap=matplotlib.cm.GnBu)\n",
    "    stop = timeit.default_timer()\n",
    "    print(stop-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "#Test filtering across \n",
    "\n",
    "codefilter = sa1_lookup[sa1_lookup['SA3'].str.contains(\"Eastern Sub\")]['SA1 Suffix']\n",
    "plot_from_df('sa1_test.html',example[example['name'].isin(codefilter)],1000)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "#Merge the SA1 Lookups into the dataframe to retrieve the postcode and electorate information\n",
    "\n",
    "sa1_pc = pd.read_csv('Data/POA_2011_AUST.csv')\n",
    "sa1_pc['col_for_merge'] = sa1_pc['SA1_MAINCODE_2011'].apply(lambda x: str(x))\n",
    "\n",
    "example = example.merge(sa1_pc, how=\"left\", left_on='name', right_on='col_for_merge')\n",
    "\n",
    "pc_2_elec = pd.read_csv('Data/pc_2_electorate.csv')\n",
    "pc_2_elec['postcode'] = pc_2_elec['postcode'].astype(str).str.zfill(4)\n",
    "\n",
    "example = example.merge(pc_2_elec[['postcode','Electorate']], left_on=\"POA_NAME_2011\",right_on='postcode')'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "#example = shapes_from_zip('Shapefiles/2011_POA_shape.zip')\n",
    "#example = shapes_from_zip('Shapefiles/1259030001_sla11aaust_shape.zip')\n",
    "#example = shapes_from_zip('Shapefiles/1259030001_ste11aaust_shape.zip')\n",
    "#adf = shapefile_to_dataframe(example)\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
